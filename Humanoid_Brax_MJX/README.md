# Humanoid_Brax_MJX

## 🚀 Project Overview
This project implements **Reinforcement Learning (RL) training** for a humanoid using **Brax's PPO implementation** with the **MuJoCo MJX physics engine**. The primary goal is to experiment with different gradient calculation methods, particularly in the context of **constrained optimization during contact dynamics.**

## 📂 Project Structure

```
Humanoid_Brax_MJX/
│── environments/            # Contains custom RL environments
│   ├── humanoid_env.py      # Custom Brax environment using MJX
│── models/                  # Stores the humanoid.xml MuJoCo model
│── plots/                   # Stores training plots and visualizations
│── renderer/                # Handles rendering rollouts and saving videos
│   ├── visualiser.py        # Visualization script for policy rollouts (called automatically by main.py)
│── rollouts/                # Stores rollout videos
│── savedpolicies/           # Stores trained policies
│── training/                # PPO training scripts and utilities
│── tutorials/               # Stores the original Brax tutorial notebooks
│── main.py                  # Entry point for training (calls visualiser.py at the end of training)
│── README.md                # Documentation
```
# Humanoid_Brax_MJX


## File Explanations

### **1️⃣ `environments/`** (Custom RL Environments)
- **`humanoid_env.py`**
  - Implements a **custom humanoid RL environment** using MJX.
  - Defines the **`step()`** function, which advances the simulation using MuJoCo's **constrained optimization solver**.
  - Computes:
    - **Forward reward** (encourages movement)
    - **Control cost** (penalizes excessive energy use)
    - **Termination conditions** (checks if humanoid falls)
  - This is where the physics and simulation logic resides.

### **2️⃣ `models/`** (MuJoCo Model Files)
- **`humanoid.xml`**
  - Defines the **structure, joints, actuators, and dynamics** of the humanoid.
  - Used by `humanoid_env.py` to create the simulation environment.
  - Can be modified to adjust body properties, joint constraints, and actuator strengths.

### **3️⃣ `plots/`** (Training Plots & Visualizations)
- Stores **graphs and visualizations** of training progress.
- Automatically updated as training progresses.

### **4️⃣ `renderer/`** (Handles Rendering & Video Saving)
- **`visualiser.py`**
  - **Automatically called by `main.py` at the end of training** to generate a `rollout.mp4` video.
  - Loads a trained policy and runs a **rollout** in the humanoid environment.
  - Saves rollout videos as `.mp4` in the `rollouts/` directory.
  - Uses OpenCV to save rollout videos (alternative: `mediapy.show_video()` if running in Jupyter).

### **5️⃣ `rollouts/`** (Stores Generated Rollout Videos)
- Contains **recorded `.mp4` rollout videos** of trained policies.
- Automatically generated by `visualiser.py` after training completes.

### **6️⃣ `savedpolicies/`** (Stores Trained Models)
- Stores **trained policy weights**.
- These can be loaded later for evaluation and inference.

### **7️⃣ `training/`** (PPO Training Code)
- **`train_ppo.py`**
  - Uses **Brax’s PPO implementation** to train the humanoid.
  - Computes **policy gradients** via JAX automatic differentiation.
  - Periodically saves **rollout videos** to track learning progress.

### **8️⃣ `tutorials/`** (Brax Tutorials & Reference Files)
- Stores **original Brax tutorial notebooks**.
- Useful for understanding Brax’s built-in training implementations.

### **9️⃣ `main.py`** (Project Entry Point)
- **Starts training by calling `train_ppo.py`**.
- At the end of training, **automatically calls `visualiser.py`** to generate and save a `rollout.mp4`.
- Designed to be the **single command execution point** for running an entire training session.

### **🔍 Running the Project**

#### **1️⃣ Setup Environment**
```bash
conda activate mjx  # Ensure you are in the correct conda environment
```

#### **2️⃣ Train the Humanoid with PPO**
```bash
python3 main.py
```
- This will start training using PPO and save progress.
- Check training plots in `plots/` to visualize learning.
- At the end of training, `main.py` will **automatically generate a rollout.mp4** in `rollouts/`.

#### **3️⃣ Visualize a Trained Policy Manually**
If needed, you can manually re-run visualization:
```bash
python3 renderer/visualiser.py --model-path path/to/saved/model
```

## 📖 Understanding MuJoCo & MJX
- **MuJoCo simulates physics using constrained optimization**.
- **Contact gradients are unstable** due to iterative solvers (Newton’s method).
- Future work: Implement **finite difference gradients** using `custom_vjp`.

## 🔍 Next Steps
- 🔲 **Test different solvers in MuJoCo MJX.**
- 🔲 **Implement finite difference gradient calculation.**
- 🔲 **Benchmark gradient stability across different training runs.**

---

This README provides a **comprehensive overview** of the project. Let me know if you'd like anything modified! 🚀

